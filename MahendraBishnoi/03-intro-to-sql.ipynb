{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Getting Started with SQL and BigQuery\n[Tutorial Link](https://www.kaggle.com/dansbecker/getting-started-with-sql-and-bigquery) <br/>\n[Notebook Link](https://www.kaggle.com/mahendrabishnoi2/03-intro-to-sql/) on kaggle.\n\n## Introduction\n- **SQL**(Structured Query Language) - A programming language used with databases. <br>\n- **BigQuery** - A web service that lets us apply SQL to huge datasets.\n\nIn this tutorial we will learn about accessing and examining BigQuery datasets.\n\n## First BigQuery commands\nTo use BigQuery we will import the Python package."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from google.cloud import bigquery","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First step in the workflow is to create a `Client` objct. `Client` object plays a central role in retrieving information from bigquery datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a client object\nclient = bigquery.Client()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will work with dataset of posts on [Hacker News](https://news.ycombinator.com/)\n\nIn BigQuery each dataset in contained in a corresponding project. In this case `hacker_news` dataset is contained in the `bigquery-public-data` project. To access the dataset,\n- Construct a reference to the dataset by using `dataset()` method.\n- Next, use the `get_dataset()` method, along with the reference we just constructed, to fetch the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct a reference to the hacker_news dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each dataset is a collection of tables.\n\nWe use `list_tables()` method to list tables present in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# List tables present in \"hacker_news\" dataset\ntables = list(client.list_tables(dataset))\n\n# print names of all tables present in the dataset\nfor table in tables:\n    print(table.table_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similar to how we fetched a dataset, we can fetch a table. In the code below we fetch the `full` table in the `hacker_news` dataset using `get_table()` method."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a table reference (\"full\")\ntable_ref = dataset_ref.table(\"full\")\n\n# API request - fetch the full table\ntable = client.get_table(table_ref)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What we have learnt so far:\n<img src=\"https://i.imgur.com/biYqbUB.png\"/>\n\n## Table Schema\nStructure of a table is called its schema. We need to understand a table's schema to pull the data we want.\n\nHere we will investigate the `full` table that we fetched earlier."},{"metadata":{"trusted":true},"cell_type":"code","source":"table.schema","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each `SchemaField` tells us about a specific column (also referred to as `field`). In order the information is:\n- The **name** of the column\n- The **field type** (or **data type**) of the column\n- The **mode** of the column (`NULLABLE` means the column allows NULL values, default)\n- A **description** of the data in that column\n\nThe first **field** has the `SchemaField`:\n`SchemaField('by', 'STRING', 'NULLABLE', \"The username of the item's author.\", ()),` <br/>\nThis tells us:\n- The **field** (or **column**) is called `by`,\n- The data in the field is strings,\n- This column allow NULL values,\n- This column contains username of item's author.\n\nWe can use `list_rows()` method to show first five rows of the `full` table to make sure its right. This returns a BigQuery `RowIterator` object which can be converted to pandas DataFrame using `to_dataframe()` method."},{"metadata":{"trusted":true},"cell_type":"code","source":"# print first five rows of the \"full\" table\nclient.list_rows(table, max_results=5).to_dataframe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above code printed out first five rows of all **fields**, we can also print first five rows of selected fields if we want. For example here we will print first five rows of `by` **field**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# print first five rows of \"by\" column (or field) of \"full\" table\nclient.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Setup**\n- import `from google.cloud import bigquery`\n- create a client object `client = bigquery.Client()\n\n**Fetching Dataset**\n- create a reference to dataset `dataset_ref = client.dataset(\"dataset_name\", project=\"project_name\")`\n- fetch dataset `dataset = client.get_dataset(dataset_ref)\n\n**List all tables present in dataset**\n- list tables `tables = list(client.list_tables(dataset))` `print(table[0].table_id)`\n\n**Fetch a table from dataset**\n- create reference to a table `table_ref = dataset_ref.table(\"table_name\")`\n- fetch table `table = client.get_table(table_ref)`\n\n**Schema**\n- schema of a table `table.schema`\n\n**List rows**\n- all rows `client.list_rows(table, max_results=5).to_dataframe()`\n- specific columns `client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()`"},{"metadata":{},"cell_type":"markdown","source":"Exercises of this tutorial are solved [here](https://www.kaggle.com/mahendrabishnoi2/exercise-getting-started-with-sql-and-bigquery)"},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":"# SELECT, FROM & WHERE\n[Tutorial Link](https://www.kaggle.com/dansbecker/select-from-where)\n\nNow that we know how to access and examine a dataset, we will start writing SQL queries. SQL queries help us sort through massive datasets, to retrieve only the information we want.\n\nIn this tutorial we will **SELECT**, **FROM** and **WHERE** to get data from specific columns based on specified conditions.\n\nWe will work with an small imaginary dataset `pet_records` which contains just one table, called `pets`.\n<img src=\"https://i.imgur.com/fI5Pvvp.png\"/>\n\n## SELECT ... FROM\nThe most basic SQL query selects single column from a table. To do this \n- specify the column you want after the word **SELECT**, and then\n- specify the table after the word **FROM**\n\nTo select the `Name` column (from the `pets` table, in the `pet_records` databse in the `bigquery-public-data` project), our query would appear as follows:\n<img src=\"https://i.imgur.com/c3GxYRt.png\"/>\n\n> Note: When writing a SQL query, the argument passed to **FROM** is not in single or double quotation marks (' or \"). Its in backticks (\\`).\n\n## WHERE\nBigQuery datasets are huge, so we'll usually want to return rows meeting specific conditions. We can do so using the **WHERE** clause.\n\nThe query below returns the entries from the `name` column that are in rows where the `Animal` column has the text `Cat`.\n<img src=\"https://i.imgur.com/HJOT8Kb.png\"/>\n"},{"metadata":{},"cell_type":"markdown","source":"## Example: Where all the the US citites in the OpenAQ dataset?\nWe'll use [OpenAQ](https://openaq.org/) dataset about air quality. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# imports \nfrom google.cloud import bigquery\n\n# create a client object \nclient = bigquery.Client()\n\n# create a dataset reference (to openaq)\ndataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n\n# api request - fetch data\ndataset = client.get_dataset(dataset_ref)\n\n# create a list of tables present in the dataset\ntables = list(client.list_tables(dataset))\n\n# print all table names\nfor table in tables:\n    print(table.table_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct a reference to the table\ntable_ref = dataset_ref.table(\"global_air_quality\")\n\n# api request - fetch table\ntable = client.get_table(table_ref)\n\n# print first five rows / lines of \"global_air_quality\" table\nclient.list_rows(table, max_results=5).to_dataframe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Write a query to select `city` column from `global_air_quality` table where `country` is `US`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Query to select all the items from the \"city\" column where the \"country\" column is 'US'\nquery = \"\"\"\n        SELECT city\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submitting the query to the dataset\n- Create a client object"},{"metadata":{"trusted":true},"cell_type":"code","source":"client = bigquery.Client()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we set up the query with the `query()` method. We will run the method with the default parameters but this method allows us to specify complicated settings as shown in [documentation](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.client.Client.query.html#google.cloud.bigquery.client.Client.query)."},{"metadata":{"trusted":true},"cell_type":"code","source":"query_job = client.query(query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we run the query and convert results to a pandas dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# api request - run the query and return a pandas DataFrame\nus_cities = query_job.to_dataframe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_cities.city.value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## More queries\nIf we want multiple columns we can select them with comma"},{"metadata":{"trusted":true},"cell_type":"code","source":"query = \"\"\"\n        SELECT city, country\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country=\"US\"\n        \"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we want to select all columns we can use `*`"},{"metadata":{"trusted":true},"cell_type":"code","source":"query = \"\"\"\n        SELECT *\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country=\"US\"\n        \"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Working with Big Datasets\nTo avoid scanning too much data at once, we can estimate size of query before we run it. We will see how to estimate query size on very large `hacker_news` dataset.\n\nTo see how much data a query will scan, we create a `QueryJobConfig` object and set the `dry_run` parameter to `True`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# query to get the score column from every row where the type column has value \"job\"\nquery = \"\"\"\n        SELECT score, title\n        FROM `bigquery-public-data.hacker_news.full`\n        WHERE type = \"job\" \n        \"\"\"\n\n# create 'QueryJobConfig' object to estimate size of query without running it\ndry_run_config = bigquery.QueryJobConfig(dry_run=True)\n\n# api request - dry run query to estimate costs\ndry_run_query_job = client.query(query, job_config=dry_run_config)\n\nprint(\"This query will process {} bytes\".format(dry_run_query_job.total_bytes_processed))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also specify a parameter when running the query to limit how much data we want to scan. Here's an example with a low limit."},{"metadata":{"trusted":true},"cell_type":"code","source":"max_size = 1 \nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=max_size)\n\n# setup the query (only run if its less than 100 MB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# api request - run the query and return a pandas dataframe\nsafe_query_job.to_dataframe()\n\n\n# strangely this query runs (need to take a look on documentation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only run the query if it's less than 1 GB\nONE_GB = 1000*1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n\n# Set up the query (will only run if it's less than 1 GB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\njob_post_scores = safe_query_job.to_dataframe()\n\n# Print average score for job posts\njob_post_scores.score.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exercises of this tutorial are solved [here](https://www.kaggle.com/mahendrabishnoi2/exercise-select-from-where)"},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Group By, Having & Count\n[Tutorial Link](https://www.kaggle.com/dansbecker/group-by-having-count)\n\nNow that we know how to select raw data, we will learn how to group selected data and count things within those groups to answer questions like: \n- How many of each kind of fruit has our store sold?\n- How many species of animal has the vet office treated?\n\n"},{"metadata":{},"cell_type":"markdown","source":"In this tutorial we will learn about **GROUP BY**, **HAVING** & **COUNT()**. We will be using following made-up table to understand these techniques\n<img src=\"https://i.imgur.com/fI5Pvvp.png\"/>"},{"metadata":{},"cell_type":"markdown","source":"## COUNT()\n**COUNT()**, as the name suggests return the count of things. If we pass name of a column to **COUNT()**, it will return number of items in that column.\n\nFor example if we **SELECT** the **COUNT()** of `ID` columns in `pets` table, it will return 4, because there are 4 IDs.\n<img src=\"https://i.imgur.com/Eu5HkXq.png\"/>"},{"metadata":{},"cell_type":"markdown","source":"## GROUP BY\n**GROUP BY** takes the name of one or more columns, and treats all rows with the same value in that column as a single group when you apply aggregate functions like **COUNT()**.\n\nFor example, say we want to know how many of each type of animal we have in the `pets` table. We can use **GROUP BY** to group together rows that have the same value in the `Animal` column, while using **COUNT()** to find out how many ID's we have in each group.\n<img src=\"https://i.imgur.com/tqE9Eh8.png\"/>\nIt returns a table with three rows (one for each distinct animal). We can see that the `pets` table contains 1 rabbit, 1 dog, and 2 cats."},{"metadata":{},"cell_type":"markdown","source":"## GROUP BY ... HAVING\n**HAVING** is used in combination with **GROUP BY** to ignore groups that don't meet certain criteria.\n\nSo this query, for example, will only include groups that have more than one ID in them.\n<img src=\"https://i.imgur.com/2ImXfHQ.png\"/>"},{"metadata":{},"cell_type":"markdown","source":"## Example: Which Hacker News comments generated the most discussion?\nWe will work with `comments` table."},{"metadata":{"trusted":true},"cell_type":"code","source":"# imports \nfrom google.cloud import bigquery\n\n# create a client object\nclient = bigquery.Client()\n\n# construct a reference to the hacker_news dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# api request - fetch dataset\ndataset = client.get_dataset(dataset_ref)\n\n# list tables in the 'hacker_news' dataset\ntables = list(client.list_tables(dataset))\n\n# print all tables present in the dataset\nfor table in tables:\n    print(table.table_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct a reference to 'comments' table\ntable_ref = dataset_ref.table('comments')\n\n# api request - fetch dataset\ntable = client.get_table(table_ref)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"client.list_rows(table, max_results=5).to_dataframe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above table we can say that:\n- id column shows id of each comment\n- parent column shows the comment (id) that was replied to \n\nSo we can **GROUP BY** the `parent` and **COUNT()** the `id` column to figure out the number of replies for every comment, and since we are looking for popular comments we can apply a condition using **HAVING** to return only those comments which received more than 10 replies."},{"metadata":{"trusted":true},"cell_type":"code","source":"# query to select comments that have more than 10 replies\nquery = \"\"\"\n        SELECT parent, COUNT(id)\n        FROM `bigquery-public-data.hacker_news.comments`\n        GROUP BY parent\n        HAVING COUNT(id) > 10\n        \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set up query and QueryJobConfig (To be on safer side)\nsafe_config = bigquery.QueryJobConfig(max_bytes_billed = 10*9)       # 1 GB limit\nquery_job = client.query(query, job_config=safe_config)\n\n# api request - run the query and return a pandas dataframe\npopular_comments = query_job.to_dataframe()\n\n# print first five rows of popular_comments dataframe\npopular_comments.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Aliasing and Other Improvements\n- The column resulting from **COUNT(id)** was called `f0__`. That's not a very descriptive name. We can change the name by adding `AS NumPosts` after we specify the aggregation.\n- If we are ever unsure what to put inside the **COUNT()** function, we can do **COUNT(1)** to count the rows in each group. Most people find it especially readable, because we know it's not focusing on other columns. It also scans less data than if supplied column names (making it faster and using less of our data access quota(BigQuery 30 TB quota))."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imporoved version of earlier query with aliasing and improved readability\nquery_improved = \"\"\"\n                 SELECT parent, COUNT(1) AS NumPosts\n                 FROM `bigquery-public-data.hacker_news.comments`\n                 GROUP BY parent\n                 HAVING COUNT(1) > 10\n                 \"\"\"\n\n# set up query and QueryJobConfig (To be on safer side)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9) \nquery_job = client.query(query_improved, job_config=safe_config)\n\n# api request - run the query and return a pandas dataframe\nimproved_df = query_job.to_dataframe()\n\n# print first five rows of improved_df dataframe\nimproved_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Note on using **GROUP BY**\nNote that because it tells SQL how to apply aggregate functions (like **COUNT()**), it doesn't make sense to use **GROUP BY** without an aggregate function. Similarly, if we have any **GROUP BY** clause, then all variables must be passed to either a\n1. GROUP BY command, or\n2. an aggregation function."},{"metadata":{"trusted":true},"cell_type":"code","source":"query_good = \"\"\"\n             SELECT parent, COUNT(id)\n             FROM `bigquery-public-data.hacker_news.comments`\n             GROUP BY parent\n             \"\"\"\n\n# Example of a good query as parent is used with GROUP BY and id is used with COUNT()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_bad = \"\"\"\n            SELECT author, parent, COUNT(id)\n            FROM `bigquery-public-data.hacker_news.comments`\n            GROUP BY parent\n            \"\"\"\n\n# This query will throw an error because author is neither aggregated nor used with GROUP BY","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exercises of this tutorial are solved [here](https://www.kaggle.com/mahendrabishnoi2/exercise-group-by-having-count)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
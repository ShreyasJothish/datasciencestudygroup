{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Getting Started with SQL and BigQuery\n",
    "[Tutorial Link](https://www.kaggle.com/dansbecker/getting-started-with-sql-and-bigquery)\n",
    "\n",
    "## Introduction\n",
    "- **SQL**(Structured Query Language) - A programming language used with databases. <br>\n",
    "- **BigQuery** - A web service that lets us apply SQL to huge datasets.\n",
    "\n",
    "In this tutorial we will learn about accessing and examining BigQuery datasets.\n",
    "\n",
    "## First BigQuery commands\n",
    "To use BigQuery we will import the Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step in the workflow is to create a `Client` objct. `Client` object plays a central role in retrieving information from bigquery datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client object\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with dataset of posts on [Hacker News](https://news.ycombinator.com/)\n",
    "\n",
    "In BigQuery each dataset in contained in a corresponding project. In this case `hacker_news` dataset is contained in the `bigquery-public-data` project. To access the dataset,\n",
    "- Construct a reference to the dataset by using `dataset()` method.\n",
    "- Next, use the `get_dataset()` method, along with the reference we just constructed, to fetch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a reference to the hacker_news dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset is a collection of tables.\n",
    "\n",
    "We use `list_tables()` method to list tables present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List tables present in \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# print names of all tables present in the dataset\n",
    "for table in tables:\n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to how we fetched a dataset, we can fetch a table. In the code below we fetch the `full` table in the `hacker_news` dataset using `get_table()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table reference (\"full\")\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the full table\n",
    "table = client.get_table(table_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have learnt so far:\n",
    "<img src=\"https://i.imgur.com/biYqbUB.png\"/>\n",
    "\n",
    "## Table Schema\n",
    "Structure of a table is called its schema. We need to understand a table's schema to pull the data we want.\n",
    "\n",
    "Here we will investigate the `full` table that we fetched earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `SchemaField` tells us about a specific column (also referred to as `field`). In order the information is:\n",
    "- The **name** of the column\n",
    "- The **field type** (or **data type**) of the column\n",
    "- The **mode** of the column (`NULLABLE` means the column allows NULL values, default)\n",
    "- A **description** of the data in that column\n",
    "\n",
    "The first **field** has the `SchemaField`:\n",
    "`SchemaField('by', 'STRING', 'NULLABLE', \"The username of the item's author.\", ()),` <br/>\n",
    "This tells us:\n",
    "- The **field** (or **column**) is called `by`,\n",
    "- The data in the field is strings,\n",
    "- This column allow NULL values,\n",
    "- This column contains username of item's author.\n",
    "\n",
    "We can use `list_rows()` method to show first five rows of the `full` table to make sure its right. This returns a BigQuery `RowIterator` object which can be converted to pandas DataFrame using `to_dataframe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first five rows of the \"full\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code printed out first five rows of all **fields**, we can also print first five rows of selected fields if we want. For example here we will print first five rows of `by` **field**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first five rows of \"by\" column (or field) of \"full\" table\n",
    "client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "- import `from google.cloud import bigquery`\n",
    "- create a client object `client = bigquery.Client()\n",
    "\n",
    "**Fetching Dataset**\n",
    "- create a reference to dataset `dataset_ref = client.dataset(\"dataset_name\", project=\"project_name\")`\n",
    "- fetch dataset `dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "**List all tables present in dataset**\n",
    "- list tables `tables = list(client.list_tables(dataset))` `print(table[0].table_id)`\n",
    "\n",
    "**Fetch a table from dataset**\n",
    "- create reference to a table `table_ref = dataset_ref.table(\"table_name\")`\n",
    "- fetch table `table = client.get_table(table_ref)`\n",
    "\n",
    "**Schema**\n",
    "- schema of a table `table.schema`\n",
    "\n",
    "**List rows**\n",
    "- all rows `client.list_rows(table, max_results=5).to_dataframe()`\n",
    "- specific columns `client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises of this tutorial are solved [here](https://www.kaggle.com/mahendrabishnoi2/exercise-getting-started-with-sql-and-bigquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
